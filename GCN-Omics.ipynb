{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "\n",
    "G=nx.Graph()\n",
    "\n",
    "node2id = {}\n",
    "count = 0\n",
    "\n",
    "file = open(\"string/9606.protein.actions.v11.0.txt\")\n",
    "reader = csv.reader(file, delimiter='\\t')\n",
    "firstline = True\n",
    "for column in reader:\n",
    "    if firstline:\n",
    "        firstline = False\n",
    "    else:\n",
    "        n1 = -1\n",
    "        n2 = -1\n",
    "        if column[0] in node2id:\n",
    "            n1 = node2id[column[0]]\n",
    "        else:\n",
    "            node2id[column[0]] = count\n",
    "            n1 = count\n",
    "            count += 1\n",
    "\n",
    "        if column[1] in node2id:\n",
    "            n2 = node2id[column[1]]\n",
    "        else:\n",
    "            node2id[column[1]] = count\n",
    "            n2 = count\n",
    "            count += 1\n",
    "\n",
    "        G.add_node(n1)\n",
    "        G.add_node(n2)\n",
    "        score = int(column[6])\n",
    "        if score>=700:\n",
    "            G.add_edge(n1, n2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "file = open(\"string/9606.protein.aliases.v11.0.txt\")\n",
    "reader = csv.reader(file, delimiter='\\t')\n",
    "firstline = True\n",
    "gene2protein = {}\n",
    "for col in reader:\n",
    "    if firstline:\n",
    "        firstline = False\n",
    "    else:\n",
    "        prot = col[0]\n",
    "        gene = col[1]\n",
    "        if gene.find(\"ENSG\")>-1 and prot in node2id:\n",
    "            gene2protein[gene] = prot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch_geometric.utils as util\n",
    "\n",
    "data = util.from_networkx(G)\n",
    "\n",
    "degree = nx.degree(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 16061, 16062, 16063],\n",
       "        [    2,     3,     6,  ..., 13505,  5019,   853]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16073"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.ones(data.num_nodes, 1)\n",
    "data.x = X\n",
    "\n",
    "Y = torch.ones(data.num_nodes,1)\n",
    "for i in range(0,data.num_nodes):\n",
    "    Y[i,0] = degree[i]\n",
    "data.y = Y\n",
    "\n",
    "mask1 = torch.ones(data.num_nodes, dtype=bool)\n",
    "mask2 = torch.ones(data.num_nodes, dtype=bool)\n",
    "mask3 = torch.ones(data.num_nodes, dtype=bool)\n",
    "for i in range(0,int(data.num_nodes*0.8)):\n",
    "    mask1[i] = True\n",
    "    mask2[i] = False\n",
    "for i in range(int(data.num_nodes*0.8), data.num_nodes):\n",
    "    mask1[i] = False\n",
    "    mask2[i] = True\n",
    "data.train_mask = mask1\n",
    "data.test_mask = mask2\n",
    "Y = Y / torch.max(Y)\n",
    "data.y = Y\n",
    "X = Y\n",
    "#data.x = X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import csv\n",
    "import os\n",
    "\n",
    "xs = []\n",
    "count = 0\n",
    "for i in [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"cancer/\")) for f in fn]:\n",
    "    if str(i).find(\"FPKM-UQ\") > -1 and count < 2:\n",
    "        count += 1\n",
    "        file = gzip.open(i, mode=\"rt\")\n",
    "        csvobj = csv.reader(file, delimiter = '\\t')\n",
    "        localX = torch.zeros(data.num_nodes, 1)\n",
    "        for line in csvobj:\n",
    "            gene = line[0].split(\".\")[0]\n",
    "            if gene in gene2protein:\n",
    "                protein = gene2protein[gene]\n",
    "                nodeid = node2id[protein]\n",
    "                evalue = float(line[1])\n",
    "                #print(gene + \" is not missing: \" + protein + \" with id \" + str(nodeid))\n",
    "                localX[nodeid] = evalue\n",
    "            else:\n",
    "                continue\n",
    "        xs.append(localX)\n",
    "Xs = torch.stack(xs)\n",
    "Xs = Xs / torch.max(Xs)\n",
    "data.x = Xs\n",
    "data.y = Xs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4942, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor(0.3639, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 tensor(0.2198, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 tensor(0.1066, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 tensor(0.0467, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(0.0215, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 tensor(0.0107, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 tensor(0.0057, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 tensor(0.0035, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 tensor(0.0024, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 32, improved=True)\n",
    "        self.conv2 = GCNConv(32, 1, improved=True)\n",
    "\n",
    "    def forward(self, data): # should really be trained in batches somehow, probably a terrible hack\n",
    "        xlist, edge_index = data.x, data.edge_index\n",
    "        out = []\n",
    "        for i in range(0, len(xlist)):\n",
    "            x = xlist[i]\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            out.append(torch.sigmoid(x))\n",
    "        return torch.stack(out)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data_run = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_run)\n",
    "    #### SUM UP HERE\n",
    "    loss = float(0.0)\n",
    "    for i in range(0,len(data_run.x)):\n",
    "        localloss= F.mse_loss(out[i][data_run.train_mask], data_run.y[i][data_run.train_mask])\n",
    "        loss += localloss\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "name": "GCN-Omics.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

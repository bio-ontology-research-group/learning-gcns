{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "# optimized version of the standard GCN model\n",
    "class MyGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_index, num_nodes, improved=False, cached=False,\n",
    "                 bias=True, normalize=True, **kwargs):\n",
    "        super(MyGCNConv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.edge_index = edge_index\n",
    "        self.edge_index, self.norm = self.norm(edge_index, self.num_nodes, improved=True)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "\n",
    "    @staticmethod\n",
    "    def norm(edge_index, num_nodes, edge_weight=None, improved=False,\n",
    "             dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "\n",
    "        fill_value = 1 if not improved else 2\n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "\n",
    "    def forward(self, x, edge_weight=None):\n",
    "        \"\"\"\"\"\"\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        return self.propagate(self.edge_index, x=x, norm=self.norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j if norm is not None else x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read protein interactions\n",
    "\n",
    "import networkx as nx\n",
    "import csv\n",
    "\n",
    "G=nx.Graph()\n",
    "\n",
    "node2id = {}\n",
    "count = 0\n",
    "\n",
    "file = open(\"string/9606.protein.actions.v11.0.txt\")\n",
    "reader = csv.reader(file, delimiter='\\t')\n",
    "firstline = True\n",
    "for column in reader:\n",
    "    if firstline:\n",
    "        firstline = False\n",
    "    else:\n",
    "        n1 = -1\n",
    "        n2 = -1\n",
    "        if column[0] in node2id:\n",
    "            n1 = node2id[column[0]]\n",
    "        else:\n",
    "            node2id[column[0]] = count\n",
    "            n1 = count\n",
    "            count += 1\n",
    "\n",
    "        if column[1] in node2id:\n",
    "            n2 = node2id[column[1]]\n",
    "        else:\n",
    "            node2id[column[1]] = count\n",
    "            n2 = count\n",
    "            count += 1\n",
    "\n",
    "        G.add_node(n1)\n",
    "        G.add_node(n2)\n",
    "        score = int(column[6])\n",
    "        if score>=700:\n",
    "            G.add_edge(n1, n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read map of gene ids to protein ids, map to nodes\n",
    "file = open(\"string/9606.protein.aliases.v11.0.txt\")\n",
    "reader = csv.reader(file, delimiter='\\t')\n",
    "firstline = True\n",
    "gene2protein = {}\n",
    "for col in reader:\n",
    "    if firstline:\n",
    "        firstline = False\n",
    "    else:\n",
    "        prot = col[0]\n",
    "        gene = col[1]\n",
    "        if gene.find(\"ENSG\")>-1 and prot in node2id:\n",
    "            gene2protein[gene] = prot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate PyTorch datastructure from networkx\n",
    "\n",
    "import torch_geometric.utils as util\n",
    "import gzip\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "\n",
    "network = util.from_networkx(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the cancer data -> read in tensor of shape NumSamples x NumNodes x NumFeatures [NumFeatures == 1]\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "dataset = []\n",
    "dataset_plain = []\n",
    "count = 0\n",
    "for i in [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(\"cancer/\")) for f in fn]:\n",
    "    if str(i).find(\"FPKM-UQ\") > -1 and count < 20:\n",
    "        count += 1\n",
    "        file = gzip.open(i, mode=\"rt\")\n",
    "        csvobj = csv.reader(file, delimiter = '\\t')\n",
    "        localX = torch.zeros(network.num_nodes,1)\n",
    "        for line in csvobj:\n",
    "            gene = line[0].split(\".\")[0]\n",
    "            if gene in gene2protein:\n",
    "                protein = gene2protein[gene]\n",
    "                nodeid = node2id[protein]\n",
    "                evalue = float(line[1])\n",
    "                #print(gene + \" is not missing: \" + protein + \" with id \" + str(nodeid))\n",
    "                localX[nodeid] = evalue\n",
    "            else:\n",
    "                continue\n",
    "        data = Data(x = localX, y = localX)\n",
    "        dataset.append(data)\n",
    "        dataset_plain.append(localX)\n",
    "\n",
    "# normalize\n",
    "maxval = torch.max(torch.stack(dataset_plain))\n",
    "dataset_plain = [t / maxval for t in dataset_plain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the model layout -> use custom GCN model defined above\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, edge_index, num_nodes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = MyGCNConv(1, 8, edge_index, num_nodes, node_dim = 1)\n",
    "        self.conv2 = MyGCNConv(8, 1, edge_index, num_nodes, node_dim = 1 )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x)\n",
    "        out = torch.sigmoid(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: tensor(0.2438, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: tensor(0.2310, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: tensor(0.2145, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: tensor(0.1968, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: tensor(0.1785, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCHSIZE = 10\n",
    "\n",
    "trainmask = torch.zeros(BATCHSIZE, data.num_nodes).bool().random_(0, 10)\n",
    "testmask = torch.ones(BATCHSIZE, data.num_nodes).bool()\n",
    "validationmask = torch.ones(BATCHSIZE, data.num_nodes).bool()\n",
    "for i in range(0, len(data) - 1):\n",
    "    for j in range(0, data.num_nodes):\n",
    "        if trainmask[i][j]:\n",
    "            testmask[i][j] = False\n",
    "        else:\n",
    "            testmask[i][j] = True\n",
    "\n",
    "loader = DataLoader(dataset_plain, batch_size = BATCHSIZE, shuffle = True)\n",
    "\n",
    "model = Net(network.edge_index, network.num_nodes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = F.mse_loss(out[trainmask], batch[trainmask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "        out = model(batch)\n",
    "        testloss = F.mse_loss(out[testmask], batch[testmask])\n",
    "        print(\"Epoch \" + str(epoch) + \": \" + str(testloss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
